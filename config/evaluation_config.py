"""
Configuration for model evaluation and nested cross-validation.
"""

import numpy as np
import os

# ============================================================================
# Data File Paths
# ============================================================================

# Get the root directory (parent of config/)
_CONFIG_DIR = os.path.dirname(os.path.abspath(__file__))
_ROOT_DIR = os.path.dirname(_CONFIG_DIR)
_DATA_DIR = os.path.join(_ROOT_DIR, 'data')

# SNOW-generated features (output from aggregator)
# This file is generated by the pipeline and saved in the root directory
SNOW_FEATURES_PATH = os.path.join(_ROOT_DIR, 'extracted_features_1018.csv')

# Structured features and labels (INDEX_COL and NOTES_COL imported from pipeline_config.py)
from config.SNOW_config import NOTES_FILE_PATH, INDEX_COL, NOTES_COL
STRUCTURED_FILE_PATH = os.path.join(_DATA_DIR, 'structured_features.csv')

# Label column name
LABEL_COL = 'death_30_days'  # Biological failure

# Index column for row alignment validation (None to skip validation)
# INDEX_COL and NOTES_COL imported from data_config.py

# Embedding files
# Dictionary format allows easy addition/removal of embeddings
# Keys must match embedding names used in feature sets: 'bow_classic', 'bow_tfidf', 'gemini'
EMBEDDING_FILES = {
    'bow_classic': os.path.join(_DATA_DIR, 'embeddings', 'bow_classic.csv'),
    'bow_tfidf': os.path.join(_DATA_DIR, 'embeddings', 'bow_tfidf.csv'),
    'gemini': os.path.join(_DATA_DIR, 'embeddings', 'gemini_embeddings.csv'),
    # Add more embeddings as needed:
    # 'new_embedding': 'path/to/new_embedding.csv',
}

# ============================================================================
# Additional Feature Sets (Optional)
# ============================================================================

# Add additional feature sets here as needed
# Format: 'feature_name': '/path/to/features.csv'
# When empty, no additional features are used
ADDITIONAL_FEATURES = {
    # Example:
    # 'llm_features': 'data/llm_extracted_features.csv',
    # 'manual_features': 'data/manual_annotations.csv',
    # 'clinical_scores': 'data/clinical_scores.csv',
}

# ============================================================================
# Cross-Validation Configuration
# ============================================================================

# Number of evaluation iterations with different random seeds
N_ITERATIONS = 50

# Master random seed (for generating iteration seeds)
MASTER_SEED = 2048

# Nested CV configuration
N_OUTER_FOLDS = 3  # Outer cross-validation folds
N_INNER_FOLDS = 3  # Inner cross-validation folds (for hyperparameter tuning)
INNER_CV_REPEATS = 3  # Number of repeats for inner CV (RepeatedStratifiedKFold)

# NLP Embedding dimensionality variants to test (for NLP evaluation)
# Creates trimmed versions of embeddings with these target dimensions
TARGET_DIMS = [50, 100, 200, 300]

# ============================================================================
# Imputation Configuration
# ============================================================================

# Imputation method: 'mean', 'mice', 'svd', or 'knn'
IMPUTATION_METHOD = 'mean'

# MICE (IterativeImputer) parameters
MICE_MAX_ITER = 10

# SVD imputation parameters
SVD_N_COMPONENTS = 3
SVD_MAX_ITER = 500
SVD_TOL = 1e-4

# KNN imputation parameters
KNN_N_NEIGHBORS = 5

# ============================================================================
# Model Configuration
# ============================================================================

# Models to evaluate
MODELS = {
    'LogisticRegression': {
        'class': 'sklearn.linear_model.LogisticRegression',
        'params': {
            'random_state': None,  # Will be set per iteration
            'max_iter': 3000
        },
        'param_grid': {
            'C': np.logspace(-5, 1, 7),
            'penalty': ['l1', 'l2'],
            'solver': ['liblinear', 'saga']
        }
    },
    'RandomFeature': {
        'class': 'core.ml_models.RandomFeatureModel',  # Custom model defined in core/ml_models.py
        'params': {
            'random_state': None  # Will be set per iteration
        },
        'param_grid': {
            'n_components': [256, 512, 1024, 2048, 4096],  # Properly reduced for small dataset (147 samples, ~98 in training)
            'alpha': np.logspace(-4, 4, 9)
        }
    },
    'KNN': {
        'class': 'sklearn.neighbors.KNeighborsClassifier',
        'params': {},
        'param_grid': {
            'n_neighbors': [5, 10, 20, 30, 40, 50],  # Appropriate for 147 samples
            'weights': ['uniform', 'distance'],
            'metric': ['euclidean', 'manhattan']
        }
    }
}

# ============================================================================
# Feature Set Configuration
# ============================================================================

# Feature sets to evaluate
FEATURE_SETS = {
    'Baseline': {
        'description': 'Baseline features only (from STRUCTURED_FILE_PATH, excluding LABEL)',
        'sources': ['structured']
    },
    'Baseline + SNOW': {
        'description': 'Baseline + SNOW-extracted features',
        'sources': ['structured', 'snow']
    },
    'Baseline + BoW Classic': {
        'description': 'Baseline + BoW classic embeddings',
        'sources': ['structured', 'bow_classic']
    },
    'Baseline + BoW TF-IDF': {
        'description': 'Baseline + BoW TF-IDF embeddings',
        'sources': ['structured', 'bow_tfidf']
    },
    'Baseline + Gemini Embeddings': {
        'description': 'Baseline + Gemini embeddings',
        'sources': ['structured', 'gemini']
    },
    'Baseline + RFG': {
        'description': 'Baseline + Representative Feature Generation (selects best embeddings)',
        'sources': ['structured', 'rfg']  # Special marker for multi-embedding selection with dim selection
    }
}

# ============================================================================
# Evaluation Metrics
# ============================================================================

# Primary metric for model selection
PRIMARY_METRIC = 'auc'

# Metrics to calculate
METRICS = ['auc', 'accuracy']

# ============================================================================
# Output Configuration
# ============================================================================

# Results directory
RESULTS_DIR = "evaluation_results"

# Whether to save detailed results per iteration
SAVE_DETAILED_RESULTS = True

# Whether to save feature importance
SAVE_FEATURE_IMPORTANCE = True

# ============================================================================
# Visualization Configuration
# ============================================================================

# Plot configuration
PLOT_FIGSIZE = (14, 8)
PLOT_DPI = 300

# Number of top features to show in importance plots
TOP_N_FEATURES = 20

# Box plot configuration
BOX_PLOT_COLORS = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow', 'lightpink', 'lightpurple']

# ============================================================================
# Permutation Test Configuration
# ============================================================================

# Enable permutation tests for statistical comparison of feature sets
ENABLE_PERMUTATION_TESTS = False

# Pairs of feature sets to compare: [(feature_set_1, feature_set_2), ...]
# Tests Hâ‚€: Feature Set 2 does NOT outperform Feature Set 1
# User can specify multiple pairs to test different comparisons
#
# Examples:
#   [('Baseline', 'Baseline+SNOW')]  # Test if SNOW improves over baseline
#   [('Baseline', 'Baseline+BoW'), ('Baseline', 'Baseline+TF-IDF')]  # Compare NLP embeddings
#   [('Baseline+SNOW', 'Baseline+SNOW+BoW')]  # Test incremental improvement
#
PERMUTATION_TEST_PAIRS = [
    ('Baseline', 'Baseline + SNOW'),
    ('Baseline + BoW TF-IDF', 'Baseline + SNOW'),
    ('Baseline + SNOW', 'Baseline + BoW TF-IDF')
    # Add more pairs as needed
]

# Models to run permutation tests for
# Set to None to run for all models, or specify a list of model names
# Examples:
#   None  # Run for all models
#   ['LogisticRegression']  # Only run for LogisticRegression
#   ['LogisticRegression', 'RandomFeature']  # Run for both models
PERMUTATION_TEST_MODELS = ['LogisticRegression']  # Run for all models by default

# Number of permutation iterations (B)
# Higher values give more precise p-values but take longer
# Recommended: 10,000 for final analysis, 1,000 for quick testing
PERMUTATION_N_PERMUTATIONS = 10000

# Random seed for permutation test (ensures reproducibility)
PERMUTATION_SEED = 42

# ============================================================================
# Logging Configuration
# ============================================================================

# Verbosity level (0=silent, 1=progress, 2=detailed)
VERBOSITY = 1
